{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56eb3a2-edb1-4c8b-afe5-429e037472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from math import log10, ceil\n",
    "import random, shutil, json\n",
    "from os.path import join, exists, isfile, realpath, dirname\n",
    "from os import makedirs, remove, chdir, environ\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "# import h5py\n",
    "# import faiss\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "import netvlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2964408b-b5e4-48d6-8500-2f1b5eee818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? True\n",
      "Encoder - Missing keys: []\n",
      "Encoder - Unexpected keys: []\n",
      "NetVLAD - Missing keys: []\n",
      "NetVLAD - Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Compute the cosine similarity between two VLAD encodings\"\"\"\n",
    "    v1_norm = v1 / torch.linalg.norm(v1)\n",
    "    v2_norm = v2 / torch.linalg.norm(v2)\n",
    "    return torch.dot(v1_norm, v2_norm).item()\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    return torch.dist(v1, v2, p=2).item()\n",
    "\n",
    "\n",
    "print(f'Is cuda available? {torch.cuda.is_available()}')    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load VGG16 as Encoder\n",
    "encoder_dim = 512  # VGG16 output dimension\n",
    "encoder = models.vgg16(pretrained=False)\n",
    "layers = list(encoder.features.children())[:-2]  # Use the feature extraction layers of VGG16\n",
    "encoder = nn.Sequential(*layers)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Load NetVLAD layer as pooling\n",
    "net_vlad = netvlad.NetVLAD(num_clusters=64, dim=encoder_dim, vladv2=False).to(device)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint_path = 'vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'  # Update this path with your actual checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Separate encoder and net_vlad weights\n",
    "encoder_state_dict = {k.replace('encoder.', ''): v for k, v in checkpoint['state_dict'].items() if 'encoder' in k}\n",
    "netvlad_state_dict = {k.replace('pool.', ''): v for k, v in checkpoint['state_dict'].items() if 'pool' in k}\n",
    "\n",
    "# Load the encoder state dictionary\n",
    "missing_encoder_keys, unexpected_encoder_keys = encoder.load_state_dict(encoder_state_dict, strict=False)\n",
    "print(\"Encoder - Missing keys:\", missing_encoder_keys)\n",
    "print(\"Encoder - Unexpected keys:\", unexpected_encoder_keys)\n",
    "\n",
    "# Load the NetVLAD state dictionary\n",
    "missing_vlad_keys, unexpected_vlad_keys = net_vlad.load_state_dict(netvlad_state_dict, strict=False)\n",
    "print(\"NetVLAD - Missing keys:\", missing_vlad_keys)\n",
    "print(\"NetVLAD - Unexpected keys:\", unexpected_vlad_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b3f448-b821-4f6e-b649-bf5b76f2b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for input image\n",
    "#Resize to 480 * 640 to comply ImageNet dataset\n",
    "\n",
    "#Resize, Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),  # Resize to the size used during training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet values\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#No resize, normalize\n",
    "uncompress_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet values\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bec7cd-f35b-470d-8a39-d99d19540bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for input image\n",
    "#But without normalization\n",
    "#For simplicity to construct adversarial patch\n",
    "\n",
    "#Resize, no normalize\n",
    "unnormalized_transform = transforms.Compose([\n",
    "    #we need customized resize (960,432)\n",
    "    transforms.Resize((432, 960)),  # Resize to the size used during training\n",
    "#     transforms.Resize((480, 640)),  # Resize to the size used during training\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#No resize, no normalize\n",
    "uncompress_unnormalized_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a196d9-2814-49a0-b3b7-dedd951258bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Non-normalzied version\n",
    "def image_to_tensor(image_path, compress = True, normalize = True):\n",
    "  image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "  if compress and not normalize:\n",
    "    image = unnormalized_transform(image).unsqueeze(0)  # Add batch dimension\n",
    "  elif not compress and not normalize:\n",
    "    image = uncompress_unnormalized_transform(image).unsqueeze(0)  # Add batch dimension\n",
    "  elif compress and normalize:\n",
    "    image = transform(image).unsqueeze(0)\n",
    "  elif not compress and normalize:\n",
    "    image = uncompress_transform(image).unsqueeze(0)\n",
    "  return image #which is a cpu tensor of torch.Size([1, 3, 480, 640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca74392-2c08-4ef5-bd17-69b04ffd889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra helper function for tensor -> encodings\n",
    "\n",
    "# Freeze the encoder parameters (VGG16)\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Optionally, freeze the NetVLAD parameters as well (if needed)\n",
    "for param in net_vlad.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Image tensor to encodings\n",
    "def extract_vlad_encoding_tensor(image_tensor):\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Pass the image through the VGG16 + NetVLAD model\n",
    "    encoder.eval()\n",
    "    net_vlad.eval()\n",
    "\n",
    "\n",
    "    # Pass the image through the encoder (VGG16)\n",
    "    image_encoding = encoder(image_tensor)\n",
    "\n",
    "    # Pass the encoded image through NetVLAD pooling\n",
    "    vlad_encoding = net_vlad(image_encoding)\n",
    "    # print('The shape of vlad encoding is: ', vlad_encoding.shape)\n",
    "\n",
    "    return vlad_encoding\n",
    "\n",
    "#Image file path to encodings\n",
    "def extract_vlad_encoding_path(image_path, compress = True, normalize = True):\n",
    "    # Load and preprocess the image\n",
    "    image_tensor = image_to_tensor(image_path, compress, normalize)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Pass the image through the VGG16 + NetVLAD model\n",
    "    vlad_encoding = extract_vlad_encoding_tensor(image_tensor)\n",
    "\n",
    "    return vlad_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b681e790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0031,  0.0004, -0.0052,  ...,  0.0157,  0.0036, -0.0047]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_vlad_encoding_path('checkboard_7.jpg', compress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a163c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_vlad_encoding_path('target_long_hall.png', compress = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fae263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#refer dir to KITTI\n",
    "kitti_dir = \"/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/\"\n",
    "\n",
    "#Unit test 0\n",
    "extract_vlad_encoding_path(kitti_dir + '000000.png', compress = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7eb5bf0-48d5-4334-8bcb-422271292f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between target_long_hall.png and checkboard_7.jpg: 1.1322599649429321\n"
     ]
    }
   ],
   "source": [
    "#Unit test 1\n",
    "\n",
    "# Paths to two images\n",
    "image_path_1 = 'target_long_hall.png'  # Update this with actual image paths\n",
    "image_path_2 = 'checkboard_7.jpg'  # Update this with actual image paths\n",
    "\n",
    "# Extract VLAD encodings for both images\n",
    "# Default comply to ImageNet standard\n",
    "# Compress and normalized\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1, normalize = False).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2, normalize = False).view(-1)  # Flatten the encoding\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_2}: {euclidean_distance.item()}\")\n",
    "\n",
    "\n",
    "#evaluate on extract_vlad_encoding with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffbde5a-8743-42b2-af32-5dbeb5ee9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between target_long_hall.png and checkboard_7.jpg: 1.2449448108673096\n"
     ]
    }
   ],
   "source": [
    "# Paths to two images\n",
    "image_path_1 = 'target_long_hall.png'  # Update this with actual image paths\n",
    "image_path_2 = 'checkboard_7.jpg'  # Update this with actual image paths\n",
    "\n",
    "# Extract VLAD encodings for both images\n",
    "# Default comply to ImageNet standard\n",
    "# Compress and normalized\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2).view(-1)  # Flatten the encoding\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_2}: {euclidean_distance.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582fc6e3-0588-47d7-b174-1c36c383b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between grainger_4_poster/origin_1.jpg and grainger_4_poster/origin_2.jpg: 0.426800012588501\n",
      "Euclidean distance between grainger_4_poster/patch_1.jpg and grainger_4_poster/patch_2.jpg: 0.4235435128211975\n",
      "Euclidean distance between grainger_4_poster/origin_1.jpg and grainger_4_poster/patch_1.jpg: 0.48015710711479187\n",
      "Euclidean distance between grainger_4_poster/origin_1.jpg and grainger_4_poster/patch_2.jpg: 0.4682382345199585\n"
     ]
    }
   ],
   "source": [
    "# Paths to two images\n",
    "image_path_1 = 'grainger_4_poster/origin_1.jpg'  # Update this with actual image paths\n",
    "image_path_2 = 'grainger_4_poster/origin_2.jpg'  # Update this with actual image paths\n",
    "image_path_3 = 'grainger_4_poster/patch_1.jpg'  # Update this with actual image paths\n",
    "image_path_4 = 'grainger_4_poster/patch_2.jpg'  # Update this with actual image paths\n",
    "\n",
    "# Extract VLAD encodings for both images\n",
    "# Default comply to ImageNet standard\n",
    "# Compress and normalized\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_3 = extract_vlad_encoding_path(image_path_3).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_4 = extract_vlad_encoding_path(image_path_4).view(-1)  # Flatten the encoding\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_2}: {euclidean_distance.item()}\")\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_3, vlad_encoding_4, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_3} and {image_path_4}: {euclidean_distance.item()}\")\n",
    "\n",
    "\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_3, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_3}: {euclidean_distance.item()}\")\n",
    "\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_4, p=2)\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_4}: {euclidean_distance.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c5d880-b5cc-40b0-81c2-bf2153a15612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1728, 3840])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_to_tensor('grainger_4_poster/origin_1.jpg', compress = False, normalize = False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b1f5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    return torch.dist(v1, v2, p=2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aaa063d-f378-466a-90c7-ce02e4b3682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between siebel_first_floor_loop_closure_2fps/siebel_0001.png and siebel_first_floor_loop_closure_2fps/siebel_0002.png: 0.7285271883010864\n",
      "Execution time: 0.0686 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define image paths (update as needed)\n",
    "image_path_1 = 'siebel_first_floor_loop_closure_2fps/siebel_0001.png'  # Update with actual path\n",
    "image_path_2 = 'siebel_first_floor_loop_closure_2fps/siebel_0002.png'  # Update with actual path\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Extract VLAD encodings for both images\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_2}: {euclidean_distance.item()}\")\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0159fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between /home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000000.png and /home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000001.png: 0.6734941601753235\n",
      "Execution time: 0.0217 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define image paths (update as needed)\n",
    "image_path_1 = kitti_dir + '000000.png'  # Update with actual path\n",
    "image_path_2 = kitti_dir + '000001.png'  # Update with actual path\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Extract VLAD encodings for both images\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Euclidean distance between {image_path_1} and {image_path_2}: {euclidean_distance.item()}\")\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92425df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.01218748 seconds\n",
      "Average Execution time: 0.00001219 seconds\n"
     ]
    }
   ],
   "source": [
    "# Timing multiple runs of netvlad, then average\n",
    "import time\n",
    "total_run = 1000\n",
    "\n",
    "# Define image paths (update as needed)\n",
    "image_path_1 = kitti_dir + '000000.png'  # Update with actual path\n",
    "image_path_2 = kitti_dir + '000001.png'  # Update with actual path\n",
    "\n",
    "vlad_encoding_1 = extract_vlad_encoding_path(image_path_1, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "vlad_encoding_2 = extract_vlad_encoding_path(image_path_2, compress=True, normalize=False).view(-1)  # Flatten the encoding\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(total_run):  \n",
    "    # Extract VLAD encodings for both images\n",
    "\n",
    "\n",
    "    # # Calculate Euclidean distance\n",
    "    euclidean_distance = torch.dist(vlad_encoding_1, vlad_encoding_2, p=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0677ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.8f} seconds\")\n",
    "print(f\"Average Execution time: {execution_time/total_run:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72f08b31-e15f-475f-8390-7ab847977179",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m vlad_encodings \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# vlad_encodings[image_file] = extract_vlad_encoding_path(image_file, compress = False, normalize = False).view(-1)  # Flatten the encoding\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     vlad_encodings[image_file] \u001b[38;5;241m=\u001b[39m \u001b[43mextract_vlad_encoding_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mextract_vlad_encoding_path\u001b[0;34m(image_path, compress, normalize)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_vlad_encoding_path\u001b[39m(image_path, compress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Load and preprocess the image\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m image_to_tensor(image_path, compress, normalize)\n\u001b[0;32m---> 33\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mimage_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Pass the image through the VGG16 + NetVLAD model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     vlad_encoding \u001b[38;5;241m=\u001b[39m extract_vlad_encoding_tensor(image_tensor)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    return torch.dist(v1, v2, p=2).item()\n",
    "\n",
    "# Path to the folder with images\n",
    "# image_folder = 'siebel_first_floor_loop_closure_2fps'\n",
    "image_folder = kitti_dir  # Update this with your actual folder path\n",
    "\n",
    "# Load all image file paths in the folder\n",
    "image_files = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.png')])\n",
    "\n",
    "# Ensure images were loaded\n",
    "if not image_files:\n",
    "    print(\"No PNG images found in the directory.\")\n",
    "    exit(1)\n",
    "\n",
    "# Extract VLAD encodings for all images\n",
    "vlad_encodings = {}\n",
    "for image_file in image_files:\n",
    "    # vlad_encodings[image_file] = extract_vlad_encoding_path(image_file, compress = False, normalize = False).view(-1)  # Flatten the encoding\n",
    "    vlad_encodings[image_file] = extract_vlad_encoding_path(image_file, compress = True, normalize = True).view(-1)  # Flatten the encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f6fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images in the image folder and calculate their embeddings\n",
    "def batch_vlad_encodings(image_folder = kitti_dir):\n",
    "\n",
    "    # Load all image file paths in the folder\n",
    "    image_files = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.png')])\n",
    "\n",
    "    # Ensure images were loaded\n",
    "    if not image_files:\n",
    "        print(\"No PNG images found in the directory.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Extract VLAD encodings for all imag es\n",
    "    vlad_encodings = {}\n",
    "    for image_file in image_files:\n",
    "        # vlad_encodings[image_file] = extract_vlad_encoding_path(image_file, compress = False, normalize = False).view(-1)  # Flatten the encoding\n",
    "        vlad_encodings[image_file] = extract_vlad_encoding_path(image_file, compress = True, normalize = True).view(-1)  # Flatten the encoding\n",
    "    \n",
    "    return vlad_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd7b7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541\n"
     ]
    }
   ],
   "source": [
    "vlad_encodings = batch_vlad_encodings()\n",
    "print(len(vlad_encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "270a94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    return torch.dist(v1, v2, p=2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59394660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00054938,  0.00510103,  0.00239184, ..., -0.00320269,\n",
       "        0.00455231,  0.01320232], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlad_encodings[image_files[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "830b5bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dist(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvlad_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlad_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36meuclidean_distance\u001b[0;34m(v1, v2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distance\u001b[39m(v1, v2):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mTypeError\u001b[0m: dist(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "euclidean_distance(vlad_encodings[image_files[0]], vlad_encodings[image_files[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2004ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 image has been processed\n",
      "300 image has been processed\n",
      "500 image has been processed\n",
      "700 image has been processed\n",
      "900 image has been processed\n",
      "1100 image has been processed\n",
      "1300 image has been processed\n",
      "1500 image has been processed\n",
      "1700 image has been processed\n",
      "1900 image has been processed\n",
      "2100 image has been processed\n",
      "2300 image has been processed\n",
      "2500 image has been processed\n",
      "2700 image has been processed\n",
      "2900 image has been processed\n",
      "3100 image has been processed\n",
      "3300 image has been processed\n",
      "3500 image has been processed\n",
      "3700 image has been processed\n",
      "3900 image has been processed\n",
      "4100 image has been processed\n",
      "4300 image has been processed\n",
      "4500 image has been processed\n"
     ]
    }
   ],
   "source": [
    "image_folder = kitti_dir\n",
    "image_files = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.png')])\n",
    "\n",
    "# Specify the output file\n",
    "output_file = \"netvlad_result.txt\"\n",
    "\n",
    "# Compare each image with others and compute cosine similarity\n",
    "similarity_scores = {}\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    if i % 200 == 100:\n",
    "        print(f'{i} image has been processed')\n",
    "        # break   #Early terminiation\n",
    "    image_path_1 = image_files[i]\n",
    "    vlad_encoding_1 = vlad_encodings[image_path_1]\n",
    "\n",
    "    # Compute similarity between this image and all others\n",
    "    scores = []\n",
    "    for j in range(len(image_files)):\n",
    "        # if i != j:\n",
    "        if True:\n",
    "            image_path_2 = image_files[j]\n",
    "            vlad_encoding_2 = vlad_encodings[image_path_2]\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity = euclidean_distance(vlad_encoding_1, vlad_encoding_2)\n",
    "            scores.append((image_path_2, similarity))\n",
    "\n",
    "    # Sort the scores in descending order of similarity\n",
    "    scores.sort(key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    # Store the top 20 results\n",
    "    similarity_scores[image_path_1] = scores[:20]\n",
    "\n",
    "# Output the top 20 results for each image\n",
    "with open(output_file, \"w\") as f:\n",
    "    for image_path, scores in similarity_scores.items():\n",
    "        print(f\"\\nTop 20 most similar images to {os.path.basename(image_path)}:\", file = f)\n",
    "        for idx, (similar_image, score) in enumerate(scores):\n",
    "            print(f\"{idx + 1}. {os.path.basename(similar_image)} - Eculidean Distance: {score:.4f}\", file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4de7969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_dir = \"/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b439f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Your existing functions here:\n",
    "# - extract_vlad_encoding_path() should return a PyTorch tensor or NumPy array of shape (D,).\n",
    "# - euclidean_distance() won't be needed as FAISS will handle distance calculations.\n",
    "\n",
    "\n",
    "def batch_vlad_encodings(image_folder = kitti_dir):\n",
    "    # Load all image file paths in the folder\n",
    "    image_files = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.png')])\n",
    "\n",
    "    # Ensure images were loaded\n",
    "    if not image_files:\n",
    "        print(\"No PNG images found in the directory.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Extract VLAD encodings for all images\n",
    "    vlad_encodings = {}\n",
    "    for image_file in image_files:\n",
    "        # Example: returns a PyTorch tensor. If it's a tensor, we convert it to NumPy.\n",
    "        enc = extract_vlad_encoding_path(image_file, compress=True, normalize=True).view(-1)\n",
    "        # Convert to numpy if needed\n",
    "        if hasattr(enc, 'detach'):\n",
    "            enc = enc.detach().cpu().numpy()\n",
    "        else:\n",
    "            enc = np.array(enc)\n",
    "        vlad_encodings[image_file] = enc\n",
    "    \n",
    "    return vlad_encodings, image_files\n",
    "\n",
    "vlad_encodings, image_files = batch_vlad_encodings()\n",
    "print(len(vlad_encodings))\n",
    "\n",
    "output_file = \"netvlad_result_faiss.txt\"\n",
    "\n",
    "# Convert all VLAD encodings into a single NumPy array\n",
    "embeddings = np.stack([vlad_encodings[img_path] for img_path in image_files], axis=0)\n",
    "D = embeddings.shape[1]\n",
    "\n",
    "# Build a FAISS index for efficient similarity search\n",
    "# Here we use an IndexFlatL2 which gives exact nearest neighbors based on Euclidean distance.\n",
    "index = faiss.IndexFlatL2(D)\n",
    "index.add(embeddings)  # Add all embeddings to the index\n",
    "\n",
    "# Query each image against the index\n",
    "k = 20  # number of nearest neighbors you want\n",
    "# Since we query against the same set, the image will find itself as the nearest neighbor at index 0.\n",
    "distances, indices = index.search(embeddings, k)\n",
    "\n",
    "# Write out the results\n",
    "with open(output_file, \"w\") as f:\n",
    "    for i, image_path in enumerate(image_files):\n",
    "        print(f\"\\nTop {k} most similar images to {os.path.basename(image_path)}:\", file=f)\n",
    "        for rank, neighbor_idx in enumerate(indices[i]):\n",
    "            similar_image_path = image_files[neighbor_idx]\n",
    "            distance = distances[i, rank]\n",
    "            print(f\"{rank + 1}. {os.path.basename(similar_image_path)} - Euclidean Distance: {distance:.4f}\", file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f187c4d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m vlad_encoding_2 \u001b[38;5;241m=\u001b[39m vlad_encodings[image_path_2]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvlad_encoding_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlad_encoding_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend((image_path_2, similarity))\n\u001b[1;32m     28\u001b[0m index_list\u001b[38;5;241m.\u001b[39mappend((j, similarity))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "# Specify the output file\n",
    "output_file = \"netvlad_result_bo1.txt\"\n",
    "\n",
    "# Compare each image with others and compute cosine similarity\n",
    "similarity_scores = {}\n",
    "\n",
    "similarity_list = []\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    if i % 1000 == 100:\n",
    "        print(f'{i} image has been processed')\n",
    "        # break   #Early terminiation\n",
    "    image_path_1 = image_files[i]\n",
    "    vlad_encoding_1 = vlad_encodings[image_path_1]\n",
    "\n",
    "    # Compute similarity between this image and all others\n",
    "    scores = []\n",
    "    index_list = []\n",
    "    for j in range(len(image_files)):\n",
    "        # if i != j:\n",
    "        if True:\n",
    "            image_path_2 = image_files[j]\n",
    "            vlad_encoding_2 = vlad_encodings[image_path_2]\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity = euclidean_distance(vlad_encoding_1, vlad_encoding_2)\n",
    "            scores.append((image_path_2, similarity))\n",
    "            index_list.append((j, similarity))\n",
    "\n",
    "    # Sort the scores in descending order of similarity\n",
    "    scores.sort(key=lambda x: x[1], reverse=False)\n",
    "    index_list.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "    # Store the top 20 results\n",
    "    similarity_scores[image_path_1] = scores[:20]\n",
    "    index_list_short = index_list[:10]\n",
    "\n",
    "    #Process scores\n",
    "    for matched_index, _ in index_list_short:\n",
    "        if abs(matched_index - i) > 100:\n",
    "            similarity_list.append([i, matched_index])\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88824432",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimilarity_list\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_list' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bf093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000999.png',\n",
       "  0.0),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001000.png',\n",
       "  0.6510598659515381),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000998.png',\n",
       "  0.7143281698226929),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000997.png',\n",
       "  0.7724444270133972),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001001.png',\n",
       "  0.8035771250724792),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000996.png',\n",
       "  0.819719135761261),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001002.png',\n",
       "  0.8248560428619385),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000995.png',\n",
       "  0.8309475779533386),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000994.png',\n",
       "  0.8864811658859253),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000993.png',\n",
       "  0.9308345317840576),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001003.png',\n",
       "  0.9471542835235596),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001004.png',\n",
       "  0.9545467495918274),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001013.png',\n",
       "  0.9586701989173889),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001018.png',\n",
       "  0.9591982960700989),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001012.png',\n",
       "  0.9615150094032288),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001006.png',\n",
       "  0.9656921625137329),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001032.png',\n",
       "  0.9661824107170105),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001033.png',\n",
       "  0.9693277478218079),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/000982.png',\n",
       "  0.971132755279541),\n",
       " ('/home/ds/Research/lcd/orbslam3_docker/Datasets/KITTI/data_odometry_gray/dataset/sequences/00/image_0/001011.png',\n",
       "  0.9742908477783203)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores[image_files[999]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ba562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4450],\n",
       " [1, 4451],\n",
       " [2, 4453],\n",
       " [3, 4453],\n",
       " [4, 4454],\n",
       " [5, 4455],\n",
       " [6, 4456],\n",
       " [7, 4457],\n",
       " [8, 4458],\n",
       " [9, 4459],\n",
       " [10, 4460],\n",
       " [11, 4461],\n",
       " [12, 4462],\n",
       " [13, 4463],\n",
       " [14, 4464],\n",
       " [15, 4465],\n",
       " [16, 4466],\n",
       " [17, 4467],\n",
       " [18, 4468],\n",
       " [19, 4469],\n",
       " [20, 4470],\n",
       " [21, 4471],\n",
       " [22, 4472],\n",
       " [23, 4473],\n",
       " [24, 4473],\n",
       " [25, 4474],\n",
       " [26, 4475],\n",
       " [27, 4476],\n",
       " [28, 4477],\n",
       " [29, 4478],\n",
       " [30, 4479],\n",
       " [31, 4480],\n",
       " [32, 4480],\n",
       " [33, 4482],\n",
       " [34, 4482],\n",
       " [35, 4483],\n",
       " [36, 4484],\n",
       " [37, 4485],\n",
       " [38, 4486],\n",
       " [39, 4487],\n",
       " [40, 4488],\n",
       " [41, 4489],\n",
       " [42, 4490],\n",
       " [43, 4490],\n",
       " [44, 4491],\n",
       " [45, 4492],\n",
       " [46, 4493],\n",
       " [47, 4494],\n",
       " [48, 4495],\n",
       " [49, 4496],\n",
       " [50, 4497],\n",
       " [51, 4497],\n",
       " [52, 4498],\n",
       " [53, 4499],\n",
       " [54, 4500],\n",
       " [55, 4501],\n",
       " [56, 4502],\n",
       " [57, 4503],\n",
       " [58, 4503],\n",
       " [59, 4504],\n",
       " [60, 4505],\n",
       " [61, 4506],\n",
       " [62, 4507],\n",
       " [63, 4508],\n",
       " [64, 4509],\n",
       " [65, 4509],\n",
       " [66, 4510],\n",
       " [67, 4511],\n",
       " [68, 4512],\n",
       " [69, 4512],\n",
       " [70, 4513],\n",
       " [71, 4514],\n",
       " [72, 4514],\n",
       " [73, 4515],\n",
       " [74, 4516],\n",
       " [75, 4516],\n",
       " [76, 4517],\n",
       " [77, 4518],\n",
       " [78, 4519],\n",
       " [79, 4519],\n",
       " [80, 4520],\n",
       " [81, 4520],\n",
       " [82, 4521],\n",
       " [83, 4521],\n",
       " [84, 4522],\n",
       " [85, 4523],\n",
       " [86, 4523],\n",
       " [87, 4524],\n",
       " [88, 4524],\n",
       " [89, 4525],\n",
       " [90, 4525],\n",
       " [91, 4526],\n",
       " [92, 4526],\n",
       " [93, 4526],\n",
       " [94, 4526],\n",
       " [95, 4527],\n",
       " [96, 4528],\n",
       " [97, 4528],\n",
       " [98, 4528],\n",
       " [99, 4528],\n",
       " [100, 4528],\n",
       " [101, 4528],\n",
       " [102, 4530],\n",
       " [103, 4530],\n",
       " [104, 4528],\n",
       " [105, 4527],\n",
       " [106, 4529],\n",
       " [107, 4527],\n",
       " [108, 4528],\n",
       " [109, 4528],\n",
       " [110, 4528],\n",
       " [111, 4528],\n",
       " [112, 4528],\n",
       " [113, 1586],\n",
       " [114, 1582],\n",
       " [115, 1586],\n",
       " [116, 1585],\n",
       " [117, 1585],\n",
       " [118, 1570],\n",
       " [119, 1573],\n",
       " [120, 1571],\n",
       " [121, 1571],\n",
       " [122, 1573],\n",
       " [123, 1573],\n",
       " [124, 1572],\n",
       " [125, 1572],\n",
       " [126, 1573],\n",
       " [127, 1574],\n",
       " [128, 1574],\n",
       " [129, 1576],\n",
       " [130, 1576],\n",
       " [131, 1576],\n",
       " [132, 1578],\n",
       " [133, 1579],\n",
       " [134, 1580],\n",
       " [135, 1581],\n",
       " [136, 1582],\n",
       " [137, 1582],\n",
       " [138, 1583],\n",
       " [139, 1584],\n",
       " [140, 1585],\n",
       " [141, 1586],\n",
       " [142, 1587],\n",
       " [143, 1588],\n",
       " [144, 1589],\n",
       " [145, 1590],\n",
       " [146, 1591],\n",
       " [147, 1592],\n",
       " [148, 1593],\n",
       " [149, 1594],\n",
       " [150, 1595],\n",
       " [151, 1596],\n",
       " [152, 1597],\n",
       " [153, 1597],\n",
       " [154, 1599],\n",
       " [155, 1599],\n",
       " [156, 1600],\n",
       " [157, 1601],\n",
       " [158, 1603],\n",
       " [159, 1603],\n",
       " [160, 1604],\n",
       " [161, 1605],\n",
       " [162, 1606],\n",
       " [163, 1607],\n",
       " [164, 1608],\n",
       " [165, 1609],\n",
       " [166, 1610],\n",
       " [167, 1611],\n",
       " [168, 1612],\n",
       " [169, 1613],\n",
       " [170, 1614],\n",
       " [171, 1615],\n",
       " [172, 1616],\n",
       " [173, 1616],\n",
       " [174, 1617],\n",
       " [175, 1618],\n",
       " [176, 1619],\n",
       " [177, 1620],\n",
       " [178, 1621],\n",
       " [179, 1622],\n",
       " [180, 1622],\n",
       " [181, 1623],\n",
       " [182, 1623],\n",
       " [183, 1625],\n",
       " [184, 1626],\n",
       " [185, 1626],\n",
       " [186, 1626],\n",
       " [187, 1627],\n",
       " [188, 1628],\n",
       " [189, 1629],\n",
       " [190, 1629],\n",
       " [191, 1630],\n",
       " [192, 1630],\n",
       " [193, 1631],\n",
       " [194, 1632],\n",
       " [195, 1633],\n",
       " [196, 1633],\n",
       " [197, 1634],\n",
       " [198, 1635],\n",
       " [199, 1634],\n",
       " [200, 1629],\n",
       " [201, 1627],\n",
       " [202, 1626],\n",
       " [203, 162],\n",
       " [204, 1635],\n",
       " [205, 1626],\n",
       " [206, 4375],\n",
       " [207, 4291],\n",
       " [208, 4291],\n",
       " [209, 1720],\n",
       " [210, 1306],\n",
       " [211, 1306],\n",
       " [212, 1881],\n",
       " [213, 1880],\n",
       " [214, 1979],\n",
       " [215, 1302],\n",
       " [216, 1305],\n",
       " [217, 1305],\n",
       " [218, 1307],\n",
       " [219, 1307],\n",
       " [220, 1306],\n",
       " [221, 1306],\n",
       " [222, 1307],\n",
       " [223, 1307],\n",
       " [224, 1306],\n",
       " [225, 1961],\n",
       " [226, 1322],\n",
       " [227, 1959],\n",
       " [228, 1959],\n",
       " [229, 1306],\n",
       " [230, 1269],\n",
       " [231, 1269],\n",
       " [232, 1306],\n",
       " [233, 275],\n",
       " [234, 1306],\n",
       " [235, 281],\n",
       " [236, 278],\n",
       " [237, 315],\n",
       " [238, 315],\n",
       " [239, 315],\n",
       " [240, 315],\n",
       " [241, 1307],\n",
       " [242, 3452],\n",
       " [243, 1274],\n",
       " [244, 315],\n",
       " [245, 315],\n",
       " [246, 315],\n",
       " [247, 1336],\n",
       " [248, 1336],\n",
       " [249, 1396],\n",
       " [250, 458],\n",
       " [251, 1391],\n",
       " [252, 469],\n",
       " [253, 491],\n",
       " [254, 3472],\n",
       " [255, 472],\n",
       " [256, 472],\n",
       " [257, 472],\n",
       " [258, 472],\n",
       " [259, 472],\n",
       " [260, 1349],\n",
       " [261, 3490],\n",
       " [262, 305],\n",
       " [263, 308],\n",
       " [264, 308],\n",
       " [265, 306],\n",
       " [266, 308],\n",
       " [267, 308],\n",
       " [268, 309],\n",
       " [269, 310],\n",
       " [270, 311],\n",
       " [271, 314],\n",
       " [272, 316],\n",
       " [273, 314],\n",
       " [274, 316],\n",
       " [275, 463],\n",
       " [276, 466],\n",
       " [277, 3470],\n",
       " [278, 236],\n",
       " [279, 236],\n",
       " [280, 236],\n",
       " [281, 235],\n",
       " [282, 235],\n",
       " [283, 236],\n",
       " [284, 3483],\n",
       " [285, 3483],\n",
       " [286, 3483],\n",
       " [287, 1617],\n",
       " [288, 489],\n",
       " [289, 3042],\n",
       " [290, 2569],\n",
       " [291, 2569],\n",
       " [292, 459],\n",
       " [293, 244],\n",
       " [294, 1012],\n",
       " [295, 3473],\n",
       " [296, 3748],\n",
       " [297, 232],\n",
       " [298, 364],\n",
       " [299, 236],\n",
       " [300, 3110],\n",
       " [301, 3110],\n",
       " [302, 352],\n",
       " [303, 1012],\n",
       " [304, 262],\n",
       " [305, 262],\n",
       " [306, 265],\n",
       " [307, 266],\n",
       " [308, 266],\n",
       " [309, 268],\n",
       " [310, 269],\n",
       " [311, 270],\n",
       " [312, 1336],\n",
       " [313, 260],\n",
       " [314, 271],\n",
       " [315, 272],\n",
       " [316, 275],\n",
       " [317, 275],\n",
       " [318, 1345],\n",
       " [319, 1345],\n",
       " [320, 2500],\n",
       " [321, 2520],\n",
       " [322, 2520],\n",
       " [323, 233],\n",
       " [324, 2520],\n",
       " [325, 1848],\n",
       " [326, 1848],\n",
       " [327, 3042],\n",
       " [328, 369],\n",
       " [329, 370],\n",
       " [330, 3392],\n",
       " [331, 3392],\n",
       " [332, 3392],\n",
       " [333, 3392],\n",
       " [334, 290],\n",
       " [335, 2498],\n",
       " [336, 1305],\n",
       " [337, 2495],\n",
       " [338, 3820],\n",
       " [339, 2305],\n",
       " [340, 2305],\n",
       " [341, 982],\n",
       " [342, 1821],\n",
       " [343, 3399],\n",
       " [344, 1825],\n",
       " [345, 3402],\n",
       " [346, 3403],\n",
       " [347, 2465],\n",
       " [348, 2465],\n",
       " [349, 2465],\n",
       " [350, 1848],\n",
       " [351, 302],\n",
       " [352, 302],\n",
       " [353, 2465],\n",
       " [354, 3394],\n",
       " [355, 2443],\n",
       " [356, 3396],\n",
       " [357, 3394],\n",
       " [358, 3418],\n",
       " [359, 3418],\n",
       " [360, 411],\n",
       " [361, 411],\n",
       " [362, 3418],\n",
       " [363, 3418],\n",
       " [364, 3418],\n",
       " [365, 3418],\n",
       " [366, 3418],\n",
       " [367, 412],\n",
       " [368, 2457],\n",
       " [369, 328],\n",
       " [370, 328],\n",
       " [371, 329],\n",
       " [372, 329],\n",
       " [373, 330],\n",
       " [374, 3418],\n",
       " [375, 2484],\n",
       " [376, 2472],\n",
       " [377, 2472],\n",
       " [378, 3404],\n",
       " [379, 3408],\n",
       " [380, 3408],\n",
       " [381, 2483],\n",
       " [382, 3388],\n",
       " [383, 3388],\n",
       " [384, 3402],\n",
       " [385, 2462],\n",
       " [386, 3412],\n",
       " [387, 3412],\n",
       " [388, 3412],\n",
       " [389, 3403],\n",
       " [390, 3399],\n",
       " [391, 3403],\n",
       " [392, 3403],\n",
       " [393, 3401],\n",
       " [394, 3403],\n",
       " [395, 3401],\n",
       " [396, 3404],\n",
       " [397, 3404],\n",
       " [398, 3405],\n",
       " [399, 3406],\n",
       " [400, 3407],\n",
       " [401, 2454],\n",
       " [402, 3409],\n",
       " [403, 2455],\n",
       " [404, 2456],\n",
       " [405, 2456],\n",
       " [406, 2457],\n",
       " [407, 3414],\n",
       " [408, 3414],\n",
       " [409, 3415],\n",
       " [410, 3417],\n",
       " [411, 3417],\n",
       " [412, 3418],\n",
       " [413, 3418],\n",
       " [414, 3419],\n",
       " [415, 3419],\n",
       " [416, 3422],\n",
       " [417, 3423],\n",
       " [418, 3423],\n",
       " [419, 3425],\n",
       " [420, 3426],\n",
       " [421, 3427],\n",
       " [422, 3427],\n",
       " [423, 3428],\n",
       " [424, 3429],\n",
       " [425, 3430],\n",
       " [426, 3431],\n",
       " [427, 3432],\n",
       " [428, 3432],\n",
       " [429, 3433],\n",
       " [430, 3434],\n",
       " [431, 3435],\n",
       " [432, 3436],\n",
       " [433, 3437],\n",
       " [434, 3438],\n",
       " [435, 3438],\n",
       " [436, 3439],\n",
       " [437, 3440],\n",
       " [438, 3441],\n",
       " [439, 3442],\n",
       " [440, 3443],\n",
       " [441, 3444],\n",
       " [442, 3445],\n",
       " [443, 3446],\n",
       " [444, 3447],\n",
       " [445, 3448],\n",
       " [446, 3449],\n",
       " [447, 3450],\n",
       " [448, 3451],\n",
       " [449, 3452],\n",
       " [450, 3453],\n",
       " [451, 3454],\n",
       " [452, 3455],\n",
       " [453, 3456],\n",
       " [454, 3457],\n",
       " [455, 3458],\n",
       " [456, 3459],\n",
       " [457, 3460],\n",
       " [458, 3461],\n",
       " [459, 3462],\n",
       " [460, 3463],\n",
       " [461, 3464],\n",
       " [462, 3465],\n",
       " [463, 3466],\n",
       " [464, 3467],\n",
       " [465, 3467],\n",
       " [466, 3468],\n",
       " [467, 3469],\n",
       " [468, 3470],\n",
       " [469, 3471],\n",
       " [470, 3472],\n",
       " [471, 3472],\n",
       " [472, 3473],\n",
       " [473, 3474],\n",
       " [474, 3475],\n",
       " [475, 3476],\n",
       " [476, 3476],\n",
       " [477, 3477],\n",
       " [478, 3478],\n",
       " [479, 3479],\n",
       " [480, 3479],\n",
       " [481, 3480],\n",
       " [482, 3481],\n",
       " [483, 3482],\n",
       " [484, 3482],\n",
       " [485, 3483],\n",
       " [486, 3484],\n",
       " [487, 3485],\n",
       " [488, 3486],\n",
       " [489, 3486],\n",
       " [490, 3487],\n",
       " [491, 3488],\n",
       " [492, 3489],\n",
       " [493, 3490],\n",
       " [494, 3490],\n",
       " [495, 3491],\n",
       " [496, 3492],\n",
       " [497, 3493],\n",
       " [498, 3493],\n",
       " [499, 3494],\n",
       " [500, 3495],\n",
       " [501, 3496],\n",
       " [502, 3496],\n",
       " [503, 3497],\n",
       " [504, 3498],\n",
       " [505, 3499],\n",
       " [506, 3500],\n",
       " [507, 3500],\n",
       " [508, 3501],\n",
       " [509, 3502],\n",
       " [510, 3502],\n",
       " [511, 3503],\n",
       " [512, 3504],\n",
       " [513, 3505],\n",
       " [514, 3506],\n",
       " [515, 3506],\n",
       " [516, 3507],\n",
       " [517, 3508],\n",
       " [518, 3509],\n",
       " [519, 3509],\n",
       " [520, 3510],\n",
       " [521, 3511],\n",
       " [522, 3512],\n",
       " [523, 3512],\n",
       " [524, 3515],\n",
       " [525, 3515],\n",
       " [526, 3515],\n",
       " [527, 3516],\n",
       " [528, 3517],\n",
       " [529, 3518],\n",
       " [530, 3518],\n",
       " [531, 3520],\n",
       " [532, 3520],\n",
       " [533, 3521],\n",
       " [534, 3521],\n",
       " [535, 3521],\n",
       " [536, 3521],\n",
       " [537, 3521],\n",
       " [538, 3521],\n",
       " [539, 3521],\n",
       " [540, 3521],\n",
       " [541, 3521],\n",
       " [542, 3521],\n",
       " [543, 3521],\n",
       " [544, 3521],\n",
       " [545, 3521],\n",
       " [546, 3521],\n",
       " [547, 3521],\n",
       " [548, 3521],\n",
       " [549, 3521],\n",
       " [550, 3521],\n",
       " [551, 3521],\n",
       " [552, 3521],\n",
       " [553, 3521],\n",
       " [554, 3521],\n",
       " [555, 3521],\n",
       " [556, 3521],\n",
       " [557, 3521],\n",
       " [558, 3521],\n",
       " [559, 3526],\n",
       " [560, 3524],\n",
       " [561, 3524],\n",
       " [562, 3525],\n",
       " [563, 3526],\n",
       " [564, 3525],\n",
       " [565, 3526],\n",
       " [566, 3527],\n",
       " [567, 3527],\n",
       " [568, 3527],\n",
       " [569, 3529],\n",
       " [570, 3530],\n",
       " [571, 3531],\n",
       " [572, 3531],\n",
       " [573, 3533],\n",
       " [574, 3535],\n",
       " [575, 3535],\n",
       " [576, 3537],\n",
       " [577, 3538],\n",
       " [578, 3539],\n",
       " [579, 3541],\n",
       " [580, 3541],\n",
       " [581, 3542],\n",
       " [582, 3543],\n",
       " [583, 3544],\n",
       " [584, 3545],\n",
       " [585, 3546],\n",
       " [586, 3547],\n",
       " [587, 3548],\n",
       " [588, 3549],\n",
       " [589, 3550],\n",
       " [590, 3551],\n",
       " [591, 3552],\n",
       " [592, 3552],\n",
       " [593, 3554],\n",
       " [594, 3554],\n",
       " [595, 3555],\n",
       " [596, 3556],\n",
       " [597, 3557],\n",
       " [598, 3558],\n",
       " [599, 3559],\n",
       " [600, 3560],\n",
       " [601, 3561],\n",
       " [602, 3562],\n",
       " [603, 3563],\n",
       " [604, 3563],\n",
       " [605, 3564],\n",
       " [606, 3565],\n",
       " [607, 3566],\n",
       " [608, 3567],\n",
       " [609, 3568],\n",
       " [610, 3568],\n",
       " [611, 3569],\n",
       " [612, 3570],\n",
       " [613, 3571],\n",
       " [614, 3572],\n",
       " [615, 3573],\n",
       " [616, 3573],\n",
       " [617, 3575],\n",
       " [618, 3575],\n",
       " [619, 3576],\n",
       " [620, 3577],\n",
       " [621, 3578],\n",
       " [622, 3578],\n",
       " [623, 3579],\n",
       " [624, 3580],\n",
       " [625, 3581],\n",
       " [626, 3582],\n",
       " [627, 3583],\n",
       " [628, 3584],\n",
       " [629, 3585],\n",
       " [630, 3585],\n",
       " [631, 3586],\n",
       " [632, 3587],\n",
       " [633, 3588],\n",
       " [634, 3589],\n",
       " [635, 3590],\n",
       " [636, 3591],\n",
       " [637, 3591],\n",
       " [638, 3592],\n",
       " [639, 3593],\n",
       " [640, 3594],\n",
       " [641, 3595],\n",
       " [642, 3596],\n",
       " [643, 3597],\n",
       " [644, 3597],\n",
       " [645, 3598],\n",
       " [646, 3599],\n",
       " [647, 3600],\n",
       " [648, 3601],\n",
       " [649, 3601],\n",
       " [650, 3602],\n",
       " [651, 3603],\n",
       " [652, 3604],\n",
       " [653, 3605],\n",
       " [654, 3606],\n",
       " [655, 3606],\n",
       " [656, 3607],\n",
       " [657, 3608],\n",
       " [658, 3609],\n",
       " [659, 3610],\n",
       " [660, 3611],\n",
       " [661, 3611],\n",
       " [662, 3612],\n",
       " [663, 3613],\n",
       " [664, 3614],\n",
       " [665, 3615],\n",
       " [666, 3615],\n",
       " [667, 3616],\n",
       " [668, 3617],\n",
       " [669, 3618],\n",
       " [670, 3618],\n",
       " [671, 3619],\n",
       " [672, 3620],\n",
       " [673, 3621],\n",
       " [674, 3622],\n",
       " [675, 3623],\n",
       " [676, 3624],\n",
       " [677, 3624],\n",
       " [678, 3625],\n",
       " [679, 3626],\n",
       " [680, 3627],\n",
       " [681, 3628],\n",
       " [682, 3629],\n",
       " [683, 3630],\n",
       " [684, 3630],\n",
       " [685, 3631],\n",
       " [686, 3632],\n",
       " [687, 3633],\n",
       " [688, 3634],\n",
       " [689, 3635],\n",
       " [690, 3636],\n",
       " [691, 3636],\n",
       " [692, 3637],\n",
       " [693, 3638],\n",
       " [694, 3639],\n",
       " [695, 3640],\n",
       " [696, 3641],\n",
       " [697, 3642],\n",
       " [698, 3642],\n",
       " [699, 3643],\n",
       " [700, 3644],\n",
       " [701, 3645],\n",
       " [702, 3646],\n",
       " [703, 3647],\n",
       " [704, 3648],\n",
       " [705, 3648],\n",
       " [706, 3649],\n",
       " [707, 3650],\n",
       " [708, 3651],\n",
       " [709, 3652],\n",
       " [710, 3653],\n",
       " [711, 3654],\n",
       " [712, 3654],\n",
       " [713, 3655],\n",
       " [714, 3656],\n",
       " [715, 3657],\n",
       " [716, 3658],\n",
       " [717, 3659],\n",
       " [718, 3659],\n",
       " [719, 3660],\n",
       " [720, 3660],\n",
       " [721, 3662],\n",
       " [722, 3663],\n",
       " [723, 3663],\n",
       " [724, 3664],\n",
       " [725, 3665],\n",
       " [726, 3666],\n",
       " [727, 3666],\n",
       " [728, 3668],\n",
       " [729, 3669],\n",
       " [730, 3671],\n",
       " [731, 3673],\n",
       " [732, 3673],\n",
       " [733, 3674],\n",
       " [734, 3675],\n",
       " [735, 3675],\n",
       " [736, 3677],\n",
       " [737, 3677],\n",
       " [738, 3678],\n",
       " [739, 3679],\n",
       " [740, 3680],\n",
       " [741, 3681],\n",
       " [742, 3681],\n",
       " [743, 3682],\n",
       " [744, 3683],\n",
       " [745, 3684],\n",
       " [746, 3685],\n",
       " [747, 3686],\n",
       " [748, 3687],\n",
       " [749, 3688],\n",
       " [750, 3689],\n",
       " [751, 3691],\n",
       " [752, 3692],\n",
       " [753, 3693],\n",
       " [754, 3694],\n",
       " [755, 3695],\n",
       " [756, 3695],\n",
       " [757, 3697],\n",
       " [758, 3698],\n",
       " [759, 3699],\n",
       " [760, 3700],\n",
       " [761, 3701],\n",
       " [762, 3702],\n",
       " [763, 3703],\n",
       " [764, 3703],\n",
       " [765, 3704],\n",
       " [766, 3706],\n",
       " [767, 3707],\n",
       " [768, 3707],\n",
       " [769, 3708],\n",
       " [770, 3709],\n",
       " [771, 3710],\n",
       " [772, 3711],\n",
       " [773, 3712],\n",
       " [774, 3713],\n",
       " [775, 3714],\n",
       " [776, 3715],\n",
       " [777, 3716],\n",
       " [778, 3716],\n",
       " [779, 3717],\n",
       " [780, 3718],\n",
       " [781, 3719],\n",
       " [782, 3720],\n",
       " [783, 3721],\n",
       " [784, 3722],\n",
       " [785, 3723],\n",
       " [786, 3723],\n",
       " [787, 3724],\n",
       " [788, 3725],\n",
       " [789, 3726],\n",
       " [790, 3727],\n",
       " [791, 3728],\n",
       " [792, 3729],\n",
       " [793, 3729],\n",
       " [794, 3730],\n",
       " [795, 3731],\n",
       " [796, 3732],\n",
       " [797, 3733],\n",
       " [798, 3734],\n",
       " [799, 3734],\n",
       " [800, 3735],\n",
       " [801, 3736],\n",
       " [802, 3737],\n",
       " [803, 3738],\n",
       " [804, 3739],\n",
       " [805, 3739],\n",
       " [806, 3740],\n",
       " [807, 3741],\n",
       " [808, 3742],\n",
       " [809, 3743],\n",
       " [810, 3743],\n",
       " [811, 3744],\n",
       " [812, 3745],\n",
       " [813, 3746],\n",
       " [814, 3747],\n",
       " [815, 3748],\n",
       " [816, 3748],\n",
       " [817, 3749],\n",
       " [818, 3750],\n",
       " [819, 3751],\n",
       " [820, 3752],\n",
       " [821, 3753],\n",
       " [822, 3753],\n",
       " [823, 3754],\n",
       " [824, 3755],\n",
       " [825, 3756],\n",
       " [826, 3757],\n",
       " [827, 3758],\n",
       " [828, 3758],\n",
       " [829, 3759],\n",
       " [830, 3760],\n",
       " [831, 3761],\n",
       " [832, 3761],\n",
       " [833, 3762],\n",
       " [834, 3763],\n",
       " [835, 3763],\n",
       " [836, 3764],\n",
       " [837, 3764],\n",
       " [838, 3765],\n",
       " [839, 3766],\n",
       " [840, 3767],\n",
       " [841, 3767],\n",
       " [842, 3768],\n",
       " [843, 3769],\n",
       " [844, 3769],\n",
       " [845, 3770],\n",
       " [846, 3771],\n",
       " [847, 3772],\n",
       " [848, 3772],\n",
       " [849, 3773],\n",
       " [850, 3774],\n",
       " [851, 3774],\n",
       " [852, 3775],\n",
       " [853, 3776],\n",
       " [854, 3777],\n",
       " [855, 3777],\n",
       " [856, 3778],\n",
       " [857, 3779],\n",
       " [858, 3779],\n",
       " [859, 3780],\n",
       " [860, 3781],\n",
       " [861, 3782],\n",
       " [862, 3783],\n",
       " [863, 3783],\n",
       " [864, 3784],\n",
       " [865, 3785],\n",
       " [866, 3785],\n",
       " [867, 3786],\n",
       " [868, 3787],\n",
       " [869, 3788],\n",
       " [870, 3789],\n",
       " [871, 3790],\n",
       " [872, 3790],\n",
       " [873, 3791],\n",
       " [874, 3792],\n",
       " [875, 3793],\n",
       " [876, 3794],\n",
       " [877, 3794],\n",
       " [878, 3795],\n",
       " [879, 3796],\n",
       " [880, 3797],\n",
       " [881, 3798],\n",
       " [882, 3799],\n",
       " [883, 3800],\n",
       " [884, 3800],\n",
       " [885, 3801],\n",
       " [886, 3802],\n",
       " [887, 3803],\n",
       " [888, 3804],\n",
       " [889, 3805],\n",
       " [890, 3806],\n",
       " [891, 3806],\n",
       " [892, 3807],\n",
       " [893, 3808],\n",
       " [894, 3809],\n",
       " [895, 3810],\n",
       " [896, 3810],\n",
       " [897, 3811],\n",
       " [898, 3812],\n",
       " [899, 3813],\n",
       " [900, 3814],\n",
       " [901, 3815],\n",
       " [902, 3816],\n",
       " [903, 3817],\n",
       " [904, 3818],\n",
       " [905, 3818],\n",
       " [906, 3819],\n",
       " [907, 3820],\n",
       " [908, 3821],\n",
       " [909, 3821],\n",
       " [910, 3822],\n",
       " [911, 3823],\n",
       " [912, 3824],\n",
       " [913, 3825],\n",
       " [914, 3826],\n",
       " [915, 3826],\n",
       " [916, 3827],\n",
       " [917, 3828],\n",
       " [918, 3829],\n",
       " [919, 3830],\n",
       " [920, 3830],\n",
       " [921, 3831],\n",
       " [922, 3832],\n",
       " [923, 3832],\n",
       " [924, 3833],\n",
       " [925, 3834],\n",
       " [926, 3835],\n",
       " [927, 3836],\n",
       " [928, 3836],\n",
       " [929, 3837],\n",
       " [930, 3838],\n",
       " [931, 3838],\n",
       " [932, 3839],\n",
       " [933, 3839],\n",
       " [934, 3840],\n",
       " [935, 3840],\n",
       " [936, 3841],\n",
       " [937, 3842],\n",
       " [938, 3842],\n",
       " [939, 3842],\n",
       " [940, 3843],\n",
       " [941, 3843],\n",
       " [942, 3843],\n",
       " [943, 3848],\n",
       " [944, 3846],\n",
       " [945, 3846],\n",
       " [946, 3845],\n",
       " [947, 3846],\n",
       " [948, 3846],\n",
       " [949, 3846],\n",
       " [950, 3835],\n",
       " [951, 3835],\n",
       " [952, 1626],\n",
       " [953, 1578],\n",
       " [954, 198],\n",
       " [955, 998],\n",
       " [956, 198],\n",
       " [957, 1000],\n",
       " [958, 1000],\n",
       " [959, 1000],\n",
       " [960, 162],\n",
       " [961, 190],\n",
       " [962, 190],\n",
       " [963, 1011],\n",
       " [964, 1011],\n",
       " [965, 1012],\n",
       " [966, 1010],\n",
       " [967, 1011],\n",
       " [968, 1012],\n",
       " [969, 1012],\n",
       " [970, 1012],\n",
       " [971, 4114],\n",
       " [972, 4336],\n",
       " [973, 1033],\n",
       " [974, 1033],\n",
       " [975, 1033],\n",
       " [976, 4004],\n",
       " [977, 162],\n",
       " [978, 162],\n",
       " [979, 162],\n",
       " [980, 162],\n",
       " [981, 4115],\n",
       " [982, 162],\n",
       " [983, 4070],\n",
       " [984, 3995],\n",
       " [985, 3995],\n",
       " [986, 3996],\n",
       " [987, 3219],\n",
       " [988, 3997],\n",
       " [989, 1616],\n",
       " [990, 4070],\n",
       " [991, 1043],\n",
       " [992, 1043],\n",
       " [993, 1603],\n",
       " [994, 1603],\n",
       " [995, 1603],\n",
       " [996, 1603],\n",
       " [997, 4061],\n",
       " [998, 4062],\n",
       " [999, 1603],\n",
       " ...]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netvlad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
